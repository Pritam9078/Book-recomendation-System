# -*- coding: utf-8 -*-
"""BOOK_RECOMENDATION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h5ZqpJ-st5_ZCMswvc-ntRUuN91M3lQg
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# import ipywidgets
# from ipywidgets import interact
# from ipywidgets import interact_manual
from sklearn.cluster import KMeans
from sklearn import neighbors
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

df=pd.read_csv(""C:\Users\dprit\Downloads\Book file2.csv"")

df.head()

df.tail()

df.shape

df.columns = df.columns.str.strip()

df.columns

df.dtypes

df.describe()

df2 = df.copy()

df.describe(include = 'object')

df.isnull().sum()

df.duplicated().any()

df.info()

#FEATURES ADDING

df.columns

df.isbn.nunique()

df.isbn13.nunique()

df.drop(['bookID', 'isbn', 'isbn13'], axis = 1, inplace = True)

df.columns

df.publication_date

df['year'] = df['publication_date'].str.split('/')
df['year'] = df['year'].apply(lambda x: x[2] if len(x) > 2 else None)

df.head()

df.dtypes

df.columns

df['year'].dtype
df['year'] = df['year'].astype(float)
df['year'].min()

df['year'].dtype
df['year'] = df['year'].astype(float)
df['year'].max()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

import pandas as pd
data = pd.read_csv(""C:\Users\dprit\Downloads\Book file2.csv"")
data.info()

data.info()

for column in data.columns:
    if data[column].dtype == "object":
        print(column)

import pandas as pd

# Assuming 'data' is a pandas DataFrame
data = data[pd.to_numeric(data['average_rating'], errors='coerce').notnull()]

# Define input features (X) and target variable (Y)
x = data['average_rating']
y = data['ratings_count']

# Split the data into training and testing sets (80% train, 20% test)

x

y

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

x_train

y_train

# Assuming Y_train is a pandas Series
y_train = y_train[y_train.apply(lambda x: not isinstance(x, str))]

x_test

y_test

from sklearn.linear_model import LinearRegression

x_train = x_train.to_numpy().reshape(-1, 1)
y_train = y_train.to_numpy().reshape(-1, 1)

model = LinearRegression()
model.fit(x_train, y_train)

import pandas as pd
print(type(x_train))
print(type(y_train))
print(x_train.dtype)
print(y_train.dtype)

import pandas as pd

x_train = pd.read_csv(""C:\Users\dprit\Downloads\Book file2.csv"")
x_train = pd.DataFrame(x_train)
print(x_train.head())
print(x_train.tail())
print(x_train.shape)

#ANALYSING DATA

df[df['year'] == 2020][['title', 'authors','average_rating','language_code','publisher' ]]

df.groupby(['year'])['title'].agg('count').sort_values(ascending = False).head(20)

plt.figure(figsize = (20, 10))
sns.countplot(x = 'authors', data = df,
             order = df['authors'].value_counts().iloc[:10].index)
plt.title("Top 10 Authors with maximum book publish")
plt.xticks(fontsize = 12)
plt.show()

import matplotlib.pyplot as plt
data = {
    'Graph 1': [1, 2, 3, 4, 5],
    'Graph 2': [5, 4, 3, 2, 1],
    'Graph 3': [2, 4, 6, 8, 10],
}
colors = [plt.cm.tab10(i) for i in range(len(data))]
for i, (label, values) in enumerate(data.items()):
    plt.plot(values, color=colors[i], label=label)
plt.legend()
plt.show()

df.columns

df.language_code.value_counts()

df.groupby(['language_code'])[['average_rating',
                               'ratings_count',
                               'text_reviews_count']].agg('mean').style.background_gradient(cmap = 'Wistia')

book = df['title'].value_counts()[:20]
book

# to find most occuring book in our data
plt.figure(figsize = (20, 6))
book = df['title'].value_counts()[:20]
sns.barplot(x = book.index, y = book,
           palette = 'winter_r')
plt.title("Most occuring Books")
plt.xlabel("Number of Occurance")
plt.ylabel("Books")
plt.xticks(rotation = 75, fontsize = 13)
plt.show()

sns.distplot(df['average_rating'])
plt.show()

df[df.average_rating == df.average_rating.max()][['title','authors','language_code','publisher']]

publisher = df['publisher'].value_counts()[:20]
publisher

publisher = df['publisher'].value_counts()[:20]
sns.barplot(x = publisher.index, y = publisher, palette = 'winter_r')
plt.title("Publishers")
plt.xlabel("Number of Occurance")
plt.ylabel("Publishers")
plt.xticks(rotation = 75, fontsize = 13)
plt.show()

#Recommending Books based on Publishers
#Recommending Books based on Authors
#Recommending Books based on Language

df.publisher.value_counts()

df.columns

def recomd_books_publisheres(x):
    a = df[df['publisher'] == x][['title', 'average_rating']]
    a = a.sort_values(by = 'average_rating', ascending = False)
    return a.head(10)

@interact
def recomd_books_publishers(publisher_name = list(df['publisher'].value_counts().index)):
    a = df[df['publisher'] == publisher_name][['title', 'average_rating']]
    a = a.sort_values(by = 'average_rating', ascending = False)
    return a.head(10)

df.columns

@interact
def recomd_books_authors(authors_name = list(df['authors'].value_counts().index)):
    a = df[df['authors'] == authors_name][['title', 'average_rating']]
    a = a.sort_values(by = 'average_rating', ascending = False)
    return a.head(10)

df.columns

@interact
def recomd_books_lang(language = list(df['language_code'].value_counts().index)):
    a = df[df['language_code'] == language][['title', 'average_rating']]
    a = a.sort_values(by = 'average_rating', ascending = False)
    return a.head(10)

#DATA PREPROCESSING

df.head()

def num_to_obj(x):
    if x >0 and x <=1:
        return "between 0 and 1"
    if x > 1 and x <= 2:
        return "between 1 and 2"
    if x > 2 and x <=3:
        return "between 2 and 3"
    if x >3 and x<=4:
        return "between 3 and 4"
    if x >4 and x<=5:
        return "between 4 and 5"
df['rating_obj'] = df['average_rating'].apply(num_to_obj)

df['rating_obj'].value_counts()

df.columns

language_df = pd.get_dummies(df['language_code'])
language_df.head()

features = pd.concat([rating_df,language_df, df['average_rating'],
                    df['ratings_count'], df['title']], axis = 1)
features.set_index('title', inplace= True)
features.head()

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
features_scaled = scaler.fit_transform(features)

features_scaled

#MODEL BUILDING

from sklearn import neighbors

model = neighbors.NearestNeighbors(n_neighbors=5, algorithm = 'ball_tree',
                                  metric = 'euclidean')
model.fit(features_scaled)
dist, idlist = model.kneighbors(features_scaled)

df['title'].value_counts()

from ipywidgets import interact
import pandas as pd

# Assuming you have a DataFrame named 'df' containing book information
@interact
def BookRecommender(book_name=list(df['title'].value_counts().index)):
    book_list_name = []
    book_id = df[df['title'] == book_name].index.tolist()
    book_id = book_id[0] if book_id else None

    if book_id is not None:
        # Assuming you have a list 'idlist' containing recommendations for each book id
        for newid in idlist[book_id]:
            book_list_name.append(df.iloc[newid].title)

    return book_list_name